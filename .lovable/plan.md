
# Plano: Corrigir Gera√ß√£o de Conte√∫do no kAI Chat

## Problema Identificado

A resposta do kAI Chat ao pedir "Gere um conte√∫do de LinkedIn" n√£o est√° gerando o conte√∫do real - est√° retornando descri√ß√µes abstratas sobre imagens ou respostas confusas.

**Causas raiz identificadas:**

1. **O modo selecionado via `ModeSelector` √© IGNORADO pelo `FloatingInput`** - ele determina o modo apenas pelas cita√ß√µes
2. **O pipeline `unified-content-api` s√≥ √© acionado quando `quality === "high"`**, mas a l√≥gica est√° sobrescrevendo isso
3. **Ao chamar sem cita√ß√£o de formato expl√≠cita (`@LinkedIn`)**, o sistema cai no fluxo "h√≠brido" gen√©rico que usa o `chat` comum em vez do pipeline especializado

---

## Corre√ß√µes Necess√°rias

### Corre√ß√£o 1: Passar modo do seletor para FloatingInput

O `KaiAssistantTab` usa `ModeSelector` que define `chatMode`, mas o `FloatingInput` n√£o recebe esse modo atual.

**Mudan√ßas:**
- Adicionar prop `selectedMode` ao `FloatingInput`
- Usar o modo selecionado COMO BASE, cita√ß√µes podem sobrescrev√™-lo

```text
L√≥gica corrigida:
1. Modo base = selecionado pelo ModeSelector
2. Se tem cita√ß√£o de formato ‚Üí modo "content"
3. Se tem cita√ß√£o "@ideias" ‚Üí modo "ideas"
4. Caso contr√°rio ‚Üí usa modo base
```

---

### Corre√ß√£o 2: Garantir que modo "content" SEMPRE use unified-content-api

No `useClientChat.ts`, quando `explicitMode === "content"`:
- For√ßar `shouldUseMultiAgent = true`
- Garantir que o pipeline especializado seja usado

```text
// Antes
const shouldUseMultiAgent = !isExplicitIdeaMode && (
  quality === "high" || ...
);

// Depois
const isExplicitContentMode = explicitMode === "content";
const shouldUseMultiAgent = !isExplicitIdeaMode && (
  isExplicitContentMode ||  // ‚Üê NOVO: modo expl√≠cito de conte√∫do
  quality === "high" || ...
);
```

---

### Corre√ß√£o 3: Processar resposta JSON da unified-content-api corretamente

A `unified-content-api` retorna JSON estruturado:
```json
{
  "content": "...",
  "parsed_fields": {...},
  "validation": {...},
  "sources_used": {...}
}
```

Mas o c√≥digo atual tenta parsear como stream SSE. Precisa:
1. Detectar se a resposta √© JSON
2. Extrair o campo `content`
3. Passar `sources_used` e `validation` para o payload da mensagem

---

### Corre√ß√£o 4: Melhorar detec√ß√£o de formato no prompt do usu√°rio

Quando o usu√°rio digita "Gere um conte√∫do de LinkedIn para mim", o sistema deveria detectar automaticamente que √© um pedido de conte√∫do LinkedIn mesmo sem `@LinkedIn`.

Ampliar a fun√ß√£o `detectContentType` para:
- Detectar "conte√∫do de linkedin" ‚Üí `linkedin_post`
- Detectar "conte√∫do pra linkedin" ‚Üí `linkedin_post`
- Detectar "post linkedin" ‚Üí `linkedin_post`
- Etc.

---

## Arquivos a Modificar

| Arquivo | Mudan√ßa |
|---------|---------|
| `src/components/chat/FloatingInput.tsx` | Receber `selectedMode` como prop e us√°-lo como base |
| `src/components/kai/KaiAssistantTab.tsx` | Passar `chatMode` para FloatingInput |
| `src/hooks/useClientChat.ts` | For√ßar pipeline quando `explicitMode === "content"` |
| `src/hooks/useClientChat.ts` | Corrigir parsing da resposta JSON da unified-content-api |
| `src/types/template.ts` | Melhorar `detectContentType` para detectar mais varia√ß√µes |

---

## Fluxo Corrigido

Quando usu√°rio est√° em modo **Conte√∫do** e digita "Gere um conte√∫do de LinkedIn para mim":

```text
1. FloatingInput detecta modo = "content" (do ModeSelector)
2. quality = "high" (modo content sempre usa alta qualidade)
3. useClientChat recebe explicitMode = "content"
4. shouldUseMultiAgent = true (modo expl√≠cito de conte√∫do)
5. Chama unified-content-api com:
   - format: "linkedin" (detectado do texto)
   - brief: "Gere um conte√∫do de LinkedIn para mim"
6. Resposta JSON √© parseada:
   - content ‚Üí exibido no chat
   - sources_used ‚Üí exibido no SourcesBadge
   - validation ‚Üí exibido no ValidationBadge
7. Conte√∫do final: post LinkedIn completo e formatado
```

---

## Resultado Esperado

Ap√≥s as corre√ß√µes:

**Entrada:** "Gere um conte√∫do de linkedin para mim" (modo Conte√∫do selecionado)

**Sa√≠da esperada:**
```text
üìö Fontes: Guia de Identidade ‚Ä¢ 2 itens biblioteca

[Gancho de 1 linha - aparece antes do "ver mais"]

[Espa√ßo]

[Par√°grafo 1 - Contexto ou hist√≥ria baseada no cliente]

[Espa√ßo]

[Par√°grafos 2-4 - Desenvolvimento com insights]

[Espa√ßo]

[CTA: Pergunta que gera coment√°rios]

---
üí° Ideia de imagem:
[Descri√ß√£o visual relacionada ao tema]

‚úì Validado automaticamente

üëç Usar ‚îÇ ‚úèÔ∏è Editar ‚îÇ ‚Üª Refazer ‚îÇ üìå Salvar
```

---

## Se√ß√£o T√©cnica

### Mudan√ßas espec√≠ficas no c√≥digo:

#### FloatingInput.tsx (linhas ~60 e ~213-220):
```typescript
// Props
interface FloatingInputProps {
  // ... existentes
  selectedMode?: ChatMode; // ‚Üê NOVO
}

// No handleSubmit:
let effectiveMode: ChatMode;
if (citations.some(c => c.category === "ideias" || c.id === "format_ideias")) {
  effectiveMode = "ideas";
} else if (citations.some(c => c.type === "format")) {
  effectiveMode = "content";
} else {
  effectiveMode = selectedMode || mode; // ‚Üê USA MODO SELECIONADO
}
```

#### useClientChat.ts (linhas ~1181):
```typescript
const isExplicitContentMode = explicitMode === "content";
const shouldUseMultiAgent = !isExplicitIdeaMode && (
  isExplicitContentMode || // ‚Üê NOVO
  quality === "high" || 
  extractedUrlContent !== null ||
  (MULTI_AGENT_CONTENT_TYPES.includes(earlyDetectedType || "") &&
  (selectedModel.includes("pro") || selectedModel.includes("gpt-5")))
);
```

#### useClientChat.ts (linhas ~1255-1285):
```typescript
// Processar resposta - detectar se √© JSON ou stream
if (response.headers.get("content-type")?.includes("application/json")) {
  // Resposta JSON da unified-content-api
  const jsonResponse = await response.json();
  finalContent = jsonResponse.content;
  // Salvar com metadados
  await supabase.from("messages").insert({
    // ...
    payload: {
      sources_used: jsonResponse.sources_used,
      format_type: jsonResponse.metadata?.format,
      validation: jsonResponse.validation,
    },
  });
} else {
  // Resposta SSE (stream)
  finalContent = await parseOpenAIStream(reader, {...});
}
```

#### template.ts - detectContentType:
```typescript
// Adicionar mais padr√µes para LinkedIn
if (
  lowerContent.includes("linkedin") ||
  lowerContent.includes("post linkedin") ||
  lowerContent.includes("conte√∫do de linkedin") ||
  lowerContent.includes("conte√∫do pra linkedin") ||
  lowerContent.includes("publica√ß√£o linkedin")
) {
  return "linkedin_post";
}
```
